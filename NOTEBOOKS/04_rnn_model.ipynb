{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a113ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP ###\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from SCRIPTS.config import *\n",
    "from SCRIPTS.dataprep import prepare_interval_data, TaskIntervalDataset\n",
    "from SCRIPTS.rnn_model import AttentionLSTMClassifier\n",
    "from SCRIPTS.rnn_training import create_balanced_sampler, train_rnn_model\n",
    "from SCRIPTS.cross_validation_experiments import run_rnn_cross_validation\n",
    "\n",
    "# Visualization setup\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Data path: {COMBINED_SCATTERING}\")\n",
    "print(f\"Results path: {RNN_RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURATION ###\n",
    "\n",
    "# Train RNN models? T/F\n",
    "TRAIN_RNN = False\n",
    "\n",
    "# Run cross-validation? T/F\n",
    "RUN_CROSS_VALIDATION = True\n",
    "\n",
    "# Number of CV trials (set to 5)\n",
    "CV_TRIALS = 5\n",
    "\n",
    "# Latent dimensions to test\n",
    "LATENT_DIMS = [8, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD INTERVAL DATA ###\n",
    "\n",
    "print(\"\\n=== LOADING INTERVAL DATA ===\")\n",
    "\n",
    "# Load data for different split types\n",
    "train_loader_subj, test_loader_subj, info_subj = prepare_interval_data(\n",
    "    scattering_data_path=COMBINED_SCATTERING,\n",
    "    split_type='subject',\n",
    "    batch_size=16,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader_time, test_loader_time, info_time = prepare_interval_data(\n",
    "    scattering_data_path=COMBINED_SCATTERING,\n",
    "    split_type='time',\n",
    "    batch_size=16,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nSubject split: {info_subj['n_train']} train, {info_subj['n_test']} test\")\n",
    "print(f\"Time split: {info_time['n_train']} train, {info_time['n_test']} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c238c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN RNN MODELS ###\n",
    "\n",
    "if TRAIN_RNN:\n",
    "    print(\"\\n=== TRAINING RNN MODELS ===\")\n",
    "    results = {}\n",
    "    \n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n--- Latent Dimension: {latent_dim} ---\")\n",
    "        results[latent_dim] = {}\n",
    "        \n",
    "        print(\"\\nSUBJECT WITHHOLDING:\")\n",
    "        train_dataset = train_loader_subj.dataset\n",
    "        sampler, _ = create_balanced_sampler(train_dataset)\n",
    "        train_loader_balanced = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=16, \n",
    "            sampler=sampler, \n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        model = AttentionLSTMClassifier(\n",
    "            input_dim=768,\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=128\n",
    "        )\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        model, history = train_rnn_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader_balanced,\n",
    "            test_loader=test_loader_subj,\n",
    "            num_epochs=DEFAULT_EPOCHS,\n",
    "            lr=DEFAULT_LEARNING_RATE,\n",
    "            recon_weight = LOSS_WEIGHTS['reconstruction'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results[latent_dim]['subject'] = {\n",
    "            'accuracy': history['val_acc'][-1],\n",
    "            'history': history,\n",
    "            'model_state': model.state_dict()\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        save_path = RNN_RESULTS_DIR / f'rnn_subject_{latent_dim}d.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history,\n",
    "            'latent_dim': latent_dim,\n",
    "            'split_type': 'subject'\n",
    "        }, save_path)\n",
    "        print(f\"✓ Model saved to {save_path}\")\n",
    "        \n",
    "        print(\"\\nTIME WITHHOLDING:\")\n",
    "        train_dataset_time = train_loader_time.dataset\n",
    "        sampler_time, _ = create_balanced_sampler(train_dataset_time)\n",
    "        train_loader_balanced_time = DataLoader(\n",
    "            train_dataset_time,\n",
    "            batch_size=16,\n",
    "            sampler=sampler_time,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        model = AttentionLSTMClassifier(\n",
    "            input_dim=768,\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=128\n",
    "        )\n",
    "        \n",
    "        model, history = train_rnn_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader_balanced_time,\n",
    "            test_loader=test_loader_time,\n",
    "            num_epochs=DEFAULT_EPOCHS,\n",
    "            lr=DEFAULT_LEARNING_RATE,\n",
    "            recon_weight = LOSS_WEIGHTS['reconstruction'],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results[latent_dim]['time'] = {\n",
    "            'accuracy': history['val_acc'][-1],\n",
    "            'history': history,\n",
    "            'model_state': model.state_dict()\n",
    "        }\n",
    "        \n",
    "        save_path = RNN_RESULTS_DIR / f'rnn_time_{latent_dim}d.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history,\n",
    "            'latent_dim': latent_dim,\n",
    "            'split_type': 'time'\n",
    "        }, save_path)\n",
    "        print(f\"✓ Model saved to {save_path}\")\n",
    "    \n",
    "    print(\"\\n=== RNN MODEL RESULTS ===\")\n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n{latent_dim}D Latent Space:\")\n",
    "        print(f\"  Subject: {results[latent_dim]['subject']['accuracy']:.1f}%\")\n",
    "        print(f\"  Time: {results[latent_dim]['time']['accuracy']:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"✓ Skipping RNN model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CROSS-VALIDATION ###\n",
    "\n",
    "if RUN_CROSS_VALIDATION:\n",
    "    print(f\"\\n=== CROSS-VALIDATION EXPERIMENTS ({CV_TRIALS} trials) ===\")\n",
    "\n",
    "    cv_results = {}\n",
    "\n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n--- LATENT DIMENSION: {latent_dim} ---\")\n",
    "        cv_results[latent_dim] = {}\n",
    "\n",
    "        for split_type in ['subject', 'time']:\n",
    "            print(f\"\\n{split_type.upper()} SPLIT:\")\n",
    "            cv_results[latent_dim][split_type] = run_rnn_cross_validation(\n",
    "                data_path=COMBINED_SCATTERING,\n",
    "                split_type=split_type,\n",
    "                num_trials=CV_TRIALS,\n",
    "                num_epochs=DEFAULT_EPOCHS,\n",
    "                latent_dim=latent_dim\n",
    "            )\n",
    "\n",
    "    save_path = RNN_RESULTS_DIR / 'rnn_cv_results.pkl'\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(cv_results, f)\n",
    "\n",
    "    print(f\"\\n✓ Results saved to {save_path}\")\n",
    "\n",
    "    print(\"\\n=== CROSS-VALIDATION SUMMARY ===\")\n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\nLatent Dim: {latent_dim}D\")\n",
    "        for split_type in ['subject', 'time']:\n",
    "            acc = cv_results[latent_dim][split_type]\n",
    "            print(f\"  {split_type.capitalize()}: {acc['mean_accuracy']:.1f}% ± {acc['std_accuracy']:.1f}%\")\n",
    "\n",
    "else:\n",
    "    cv_file = RNN_RESULTS_DIR / 'rnn_cv_results.pkl'\n",
    "\n",
    "    if cv_file.exists():\n",
    "        with open(cv_file, 'rb') as f:\n",
    "            cv_results = pickle.load(f)\n",
    "\n",
    "        print(\"✓ Loaded existing cross-validation results\")\n",
    "\n",
    "        print(\"\\n=== CROSS-VALIDATION SUMMARY ===\")\n",
    "        for latent_dim in cv_results:\n",
    "            print(f\"\\nLatent Dim: {latent_dim}D\")\n",
    "            for split_type in ['subject', 'time']:\n",
    "                acc = cv_results[latent_dim][split_type]\n",
    "                print(f\"  {split_type.capitalize()}: {acc['mean_accuracy']:.1f}% ± {acc['std_accuracy']:.1f}%\")\n",
    "    else:\n",
    "        print(\"✓ No existing cross-validation results found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gsth_env)",
   "language": "python",
   "name": "gsth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
