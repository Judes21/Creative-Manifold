{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f6f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/judesack/Neurospectrum_Creativity/DATA/PREPARED_FNIRS_DATA\n",
      "Scattering directory: /Users/judesack/Neurospectrum_Creativity/DATA/SCATTERING_COEFFICIENTS\n"
     ]
    }
   ],
   "source": [
    "### SETUP ###\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from SCRIPTS.config import *\n",
    "from SCRIPTS.xyzcoords import (\n",
    "    load_coordinates,\n",
    "    fix_outlier_coordinates,\n",
    "    plot_3d_adj_matrix\n",
    ")\n",
    "from SCRIPTS.dataprep import (\n",
    "    load_fnirs_data,\n",
    "    verify_data_match,\n",
    "    combine_fnirs_data,\n",
    "    generate_scatter_coefficients,\n",
    "    combine_scattering_data\n",
    ")\n",
    "\n",
    "#Visualization setup\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create directories\n",
    "create_directories()\n",
    "print(f\"Data directory: {PREPARED_FNIRS_DIR}\")\n",
    "print(f\"Scattering directory: {SCATTERING_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURATION ###\n",
    "\n",
    "# Visualize 3D adjacency matrices? T/F\n",
    "VISUALIZE_ADJACENCY = False\n",
    "\n",
    "# Generate scattering coefficients? T/F\n",
    "GENERATE_COEFFICIENTS = False\n",
    "\n",
    "#Combine fNIRS data files? T/F\n",
    "COMBINE_FNIRS = False\n",
    "\n",
    "#Combine scattering files? T/F\n",
    "COMBINE_SCATTERING = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914d8dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3D channel coordinates from .pos files...\n",
      "\n",
      "Processed 20 subjects\n",
      "Probe matrix shape: (32, 3)\n",
      "Channel matrix shape: (48, 3)\n",
      "\n",
      "Subjects found: 20\n",
      "IDs: 14073001, 14091102, 14091701, 14092201, 14101601, 15012001, 15040901, 15052902, 15053001sub1, 15053001sub2, 15072703, 15080601, 15081202sub1, 15081202sub2, 15111101, 16100101, 16100601, 16100801, 16101401, 16102002\n",
      "Replacing coords for Subject 15052902, Node 0:\n",
      "  Before: [-209.435   91.875  100.625]\n",
      "  After: [ 70.2175 -52.3625  28.575 ]\n",
      "Replacing coords for Subject 15052902, Node 3:\n",
      "  Before: [-203.655  108.15   108.975]\n",
      "  After: [ 70.2175 -52.3625  28.575 ]\n",
      "✓ Outlier coordinates fixed\n"
     ]
    }
   ],
   "source": [
    "### LOAD 3D COORDINATES ###\n",
    "\n",
    "subject_probe_coords, subject_channel_coords = load_coordinates()\n",
    "subject_ids = [subj_id for subj_id, _ in subject_channel_coords]\n",
    "print(f\"\\nSubjects found: {len(subject_ids)}\")\n",
    "print(f\"IDs: {', '.join(sorted(subject_ids))}\")\n",
    "\n",
    "# Fix known outliers\n",
    "subject_channel_coords = fix_outlier_coordinates(\n",
    "    subject_channel_coords, \n",
    "    problem_subject=\"15052902\", \n",
    "    problem_nodes=[0, 3]\n",
    ")\n",
    "print(\"✓ Outlier coordinates fixed\")\n",
    "\n",
    "if VISUALIZE_ADJACENCY  == True:\n",
    "    print(f\"\\nVisualizing 3D channel networks (threshold={THRESHOLD})...\")\n",
    "    plot_3d_adj_matrix(subject_channel_coords, threshold=THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc87b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding Subject 15081202sub1: shape (750, 48) ≠ (7850, 48)\n",
      "Excluding Subject 15072703: shape (750, 48) ≠ (7850, 48)\n",
      "\n",
      "Processed 17 subjects\n",
      "Only 17/20 subjects processed\n",
      "Subject IDs match between datasets\n",
      "✓ All subject IDs match between datasets\n"
     ]
    }
   ],
   "source": [
    "### LOAD RAW FNIRS DATA ###\n",
    "\n",
    "subject_data_matrices = load_fnirs_data()\n",
    "\n",
    "match_ok = verify_data_match(subject_channel_coords, subject_data_matrices)\n",
    "if match_ok:\n",
    "    print(\"✓ All subject IDs match between datasets\")\n",
    "else:\n",
    "    print(\"✗ Warning: Subject ID mismatch detected\")\n",
    "    \n",
    "    # Find common subjects\n",
    "    xyz_ids = {sid for sid, _ in subject_channel_coords}\n",
    "    fnr_ids = {sid for sid, _ in subject_data_matrices}\n",
    "    common = xyz_ids & fnr_ids\n",
    "    \n",
    "    subject_channel_coords = [(sid, coords) for sid, coords in subject_channel_coords if sid in common]\n",
    "    subject_data_matrices = [(sid, data) for sid, data in subject_data_matrices if sid in common]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f824beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Skipping coefficient generation (using existing files)\n"
     ]
    }
   ],
   "source": [
    "### SCATTERING COEFFICIENTS ###\n",
    "\n",
    "if GENERATE_COEFFICIENTS == True:\n",
    "    print(\"\\nGenerating scattering coefficients...\")\n",
    "    generate_scatter_coefficients(subject_channel_coords, subject_data_matrices)\n",
    "    print(\"✓ Scattering coefficients generated\")\n",
    "else:\n",
    "    print(\"✓ Skipping coefficient generation (using existing files)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c611105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding Subject 15081202sub1: shape (750, 48) ≠ (7850, 48)\n",
      "Excluding Subject 15072703: shape (750, 48) ≠ (7850, 48)\n",
      "\n",
      "Dataset: 133450 samples, 48 features\n",
      "Data saved to /Users/judesack/Neurospectrum_Creativity/DATA/PREPARED_FNIRS_DATA/combined_fnirs_data.csv\n",
      "✓ Saved to /Users/judesack/Neurospectrum_Creativity/DATA/PREPARED_FNIRS_DATA/combined_fnirs_data.csv\n",
      "\n",
      "Combined fNIRS data shape: (133450, 51)\n",
      "Features: 48 nodes\n",
      "Samples per subject: 7850\n"
     ]
    }
   ],
   "source": [
    "### COMBINE RAW FNIRS DATA ###\n",
    "\n",
    "if COMBINE_FNIRS == True:\n",
    "    fnirs_df = combine_fnirs_data()\n",
    "    print(f\"✓ Saved to {COMBINED_FNIRS}\")\n",
    "else:\n",
    "    print(f\"✓ Loading existing combined fNIRS data from {COMBINED_FNIRS}\")\n",
    "    fnirs_df = pd.read_csv(COMBINED_FNIRS)\n",
    "\n",
    "print(f\"\\nCombined fNIRS data shape: {fnirs_df.shape}\")\n",
    "print(f\"Features: {len([c for c in fnirs_df.columns if c.startswith('node_')])} nodes\")\n",
    "print(f\"Samples per subject: {len(fnirs_df[fnirs_df['subject_id'] == fnirs_df['subject_id'].iloc[0]])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730f3933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 17 subjects...\n",
      "Processing subject 15080601...\n",
      "Processing subject 15052902...\n",
      "Processing subject 16102002...\n",
      "Processing subject 14091102...\n",
      "Processing subject 16100801...\n",
      "Processing subject 16101401...\n",
      "Processing subject 14101601...\n",
      "Processing subject 14092201...\n",
      "Processing subject 15053001sub1...\n",
      "Processing subject 14091701...\n",
      "Processing subject 15040901...\n",
      "Processing subject 16100601...\n",
      "Processing subject 15111101...\n",
      "Processing subject 15081202sub2...\n",
      "Processing subject 16100101...\n",
      "Processing subject 15012001...\n",
      "Processing subject 15053001sub2...\n",
      "\n",
      "Dataset: 133450 samples, 768 features\n",
      "Task distribution:\n",
      "task\n",
      "Rest      68000\n",
      "Improv    27200\n",
      "Scale     27200\n",
      "Other     11050\n",
      "Name: count, dtype: int64\n",
      "Data saved to /Users/judesack/Neurospectrum_Creativity/DATA/SCATTERING_COEFFICIENTS/combined_scattering_data.csv\n",
      "✓ Saved to /Users/judesack/Neurospectrum_Creativity/DATA/SCATTERING_COEFFICIENTS/combined_scattering_data.csv\n",
      "\n",
      "Combined scattering data shape: (133450, 771)\n",
      "Features: 768 scattering features\n"
     ]
    }
   ],
   "source": [
    "### COMBINE SCATTERING DATA ###\n",
    "\n",
    "if COMBINE_SCATTERING == True:\n",
    "    scat_df = combine_scattering_data()\n",
    "    print(f\"✓ Saved to {COMBINED_SCATTERING}\")\n",
    "else:\n",
    "    print(f\"✓ Loading existing combined scattering data from {COMBINED_SCATTERING}\")\n",
    "    scat_df = pd.read_csv(COMBINED_SCATTERING)\n",
    "\n",
    "print(f\"\\nCombined scattering data shape: {scat_df.shape}\")\n",
    "print(f\"Features: {len([c for c in scat_df.columns if c.startswith('feature_')])} scattering features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfe83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "  fNIRS data: 0\n",
      "  Scattering data: 0\n",
      "\n",
      "Subject counts:\n",
      "  fNIRS: 17 subjects\n",
      "  Scattering: 17 subjects\n",
      "\n",
      "Data points per subject:\n",
      "  Expected: 7850 timepoints\n",
      "  fNIRS: 7850 timepoints\n",
      "  Scattering: 7850 timepoints\n"
     ]
    }
   ],
   "source": [
    "### CHECK FOR MISSING VALUES ###\n",
    "\n",
    "fnirs_missing = fnirs_df.isnull().sum().sum()\n",
    "scat_missing = scat_df.isnull().sum().sum()\n",
    "\n",
    "# Check missing NAN values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"  fNIRS data: {fnirs_missing}\")\n",
    "print(f\"  Scattering data: {scat_missing}\")\n",
    "\n",
    "# Verify subject counts\n",
    "fnirs_subjects = fnirs_df['subject_id'].nunique()\n",
    "scat_subjects = scat_df['subject_id'].nunique()\n",
    "\n",
    "print(f\"\\nSubject counts:\")\n",
    "print(f\"  fNIRS: {fnirs_subjects} subjects\")\n",
    "print(f\"  Scattering: {scat_subjects} subjects\")\n",
    "\n",
    "# Check data shapes per subject\n",
    "print(f\"\\nData points per subject:\")\n",
    "print(f\"  Expected: {EXPECTED_FNIRS_SHAPE[0]} timepoints\")\n",
    "print(f\"  fNIRS: {fnirs_df.groupby('subject_id').size().iloc[0]} timepoints\")\n",
    "print(f\"  Scattering: {scat_df.groupby('subject_id').size().iloc[0]} timepoints\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gsth_env)",
   "language": "python",
   "name": "gsth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
