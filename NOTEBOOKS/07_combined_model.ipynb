{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP ###\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append('..')\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from SCRIPTS.config import *\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from SCRIPTS.dataprep import prepare_interval_data\n",
    "from SCRIPTS.combined_model_v2 import CombinedModelV2\n",
    "from SCRIPTS.combined_training_v2 import train_combined_model_v2\n",
    "from SCRIPTS.cross_validation_experiments import run_combined_v2_cross_validation\n",
    "\n",
    "\n",
    "# Visualization setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Data path: {COMBINED_SCATTERING}\")\n",
    "print(f\"Results path: {COMBINED_MODEL_RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONFIGURATION ###\n",
    "\n",
    "# Train combined model? T/F\n",
    "TRAIN_COMBINED = False\n",
    "\n",
    "# Run cross-validation? T/F\n",
    "RUN_COMBINED_CV = True\n",
    "\n",
    "# Number of CV trials (set to 5)\n",
    "CV_TRIALS = 5\n",
    "\n",
    "# Latent dimensions to test\n",
    "LATENT_DIMS = [8, 48]\n",
    "\n",
    "# Split types\n",
    "SPLIT_TYPES = ['subject', 'time']\n",
    "\n",
    "# Number of epochs for training\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_COMBINED:\n",
    "    print(\"\\n=== TRAINING COMBINED MODELS ===\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Load interval data\n",
    "    train_loader_subj, test_loader_subj, info_subj = prepare_interval_data(\n",
    "        scattering_data_path=COMBINED_SCATTERING,\n",
    "        split_type='subject',\n",
    "        batch_size=16,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_loader_time, test_loader_time, info_time = prepare_interval_data(\n",
    "        scattering_data_path=COMBINED_SCATTERING,\n",
    "        split_type='time',\n",
    "        batch_size=16,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Subject split: {info_subj['n_train']} train, {info_subj['n_test']} test\")\n",
    "    print(f\"Time split: {info_time['n_train']} train, {info_time['n_test']} test\")\n",
    "    \n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n--- Latent Dimension: {latent_dim} ---\")\n",
    "        results[latent_dim] = {}\n",
    "        \n",
    "        print(\"\\nSUBJECT SPLIT:\")\n",
    "        model, history = train_combined_model_v2(\n",
    "            train_loader=train_loader_subj,\n",
    "            test_loader=test_loader_subj,\n",
    "            latent_dim=latent_dim,\n",
    "            split_type='subject',\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            learning_rate=DEFAULT_LEARNING_RATE,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results[latent_dim]['subject'] = {\n",
    "            'accuracy': history['final_accuracy'],\n",
    "            'history': history,\n",
    "            'model_state': model.state_dict()\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        save_path = COMBINED_MODEL_RESULTS_DIR / f'combined_v2_subject_{latent_dim}d.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history,\n",
    "            'latent_dim': latent_dim,\n",
    "            'split_type': 'subject'\n",
    "        }, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "        \n",
    "        print(\"\\nTIME SPLIT:\")\n",
    "        model, history = train_combined_model_v2(\n",
    "            train_loader=train_loader_time,\n",
    "            test_loader=test_loader_time,\n",
    "            latent_dim=latent_dim,\n",
    "            split_type='time',\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            learning_rate=DEFAULT_LEARNING_RATE,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results[latent_dim]['time'] = {\n",
    "            'accuracy': history['final_accuracy'],\n",
    "            'history': history,\n",
    "            'model_state': model.state_dict()\n",
    "        }\n",
    "        \n",
    "        save_path = COMBINED_MODEL_RESULTS_DIR / f'combined_v2_time_{latent_dim}d.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history,\n",
    "            'latent_dim': latent_dim,\n",
    "            'split_type': 'time'\n",
    "        }, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    print(\"\\n=== COMBINED MODEL V2 RESULTS ===\")\n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n{latent_dim}D Latent Space:\")\n",
    "        print(f\"  Subject: {results[latent_dim]['subject']['accuracy']:.1f}%\")\n",
    "        print(f\"  Time: {results[latent_dim]['time']['accuracy']:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping combined model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CROSS-VALIDATION ###\n",
    "\n",
    "if RUN_COMBINED_CV:\n",
    "    print(\"\\n=== COMBINED CROSS-VALIDATION ===\")\n",
    "    \n",
    "    # Use the new V2 cross-validation function\n",
    "    all_cv_results = run_combined_v2_cross_validation(\n",
    "        data_path=COMBINED_SCATTERING,\n",
    "        split_types=SPLIT_TYPES,\n",
    "        latent_dims=LATENT_DIMS,\n",
    "        num_trials=CV_TRIALS,\n",
    "        num_epochs=100  \n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== COMBINED MODEL RESULTS ===\")\n",
    "    for latent_dim in LATENT_DIMS:\n",
    "        print(f\"\\n{latent_dim}D Latent Space:\")\n",
    "        subject_key = f'subject_{latent_dim}d'\n",
    "        time_key = f'time_{latent_dim}d'\n",
    "        \n",
    "        if subject_key in all_cv_results:\n",
    "            print(f\"  Subject: {all_cv_results[subject_key]['mean_accuracy']:.1f}% ± {all_cv_results[subject_key]['std_accuracy']:.1f}%\")\n",
    "        if time_key in all_cv_results:\n",
    "            print(f\"  Time: {all_cv_results[time_key]['mean_accuracy']:.1f}% ± {all_cv_results[time_key]['std_accuracy']:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"✓ Skipping combined model cross-validation\")\n",
    "    \n",
    "    all_cv_results = {}\n",
    "    for split_type in SPLIT_TYPES:\n",
    "        for latent_dim in LATENT_DIMS:\n",
    "            config_key = f\"{split_type}_{latent_dim}d\"\n",
    "            results_file = COMBINED_MODEL_RESULTS_DIR / f'combined_v2_{split_type}_{latent_dim}d_cv_results.pkl'\n",
    "            \n",
    "            if results_file.exists():\n",
    "                with open(results_file, 'rb') as f:\n",
    "                    all_cv_results[config_key] = pickle.load(f)\n",
    "    \n",
    "    if all_cv_results:\n",
    "        print(\"\\n=== LOADED COMBINED MODEL RESULTS ===\")\n",
    "        for latent_dim in LATENT_DIMS:\n",
    "            print(f\"\\n{latent_dim}D Latent Space:\")\n",
    "            subject_key = f'subject_{latent_dim}d'\n",
    "            time_key = f'time_{latent_dim}d'\n",
    "            \n",
    "            if subject_key in all_cv_results:\n",
    "                print(f\"  Subject: {all_cv_results[subject_key]['mean_accuracy']:.1f}% ± {all_cv_results[subject_key]['std_accuracy']:.1f}%\")\n",
    "            if time_key in all_cv_results:\n",
    "                print(f\"  Time: {all_cv_results[time_key]['mean_accuracy']:.1f}% ± {all_cv_results[time_key]['std_accuracy']:.1f}%\")\n",
    "    else:\n",
    "        print(\"  No existing results found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gsth_env)",
   "language": "python",
   "name": "gsth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
